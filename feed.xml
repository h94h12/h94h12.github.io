<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Helen Huiming Han</title>
    <description>Personal website of programmer/photographer.
</description>
    <link>http://h94h12.github.io/</link>
    <atom:link href="http://h94h12.github.io/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Thu, 04 Sep 2014 13:32:07 -0700</pubDate>
    <lastBuildDate>Thu, 04 Sep 2014 13:32:07 -0700</lastBuildDate>
    <generator>Jekyll v2.3.0</generator>
    
      <item>
        <title>Optimized Raytracing</title>
        <description>&lt;p&gt;Tools: C++, SSE intrinsics, OpenMP&lt;/p&gt;

&lt;p&gt;Using techniques from my Engineering Parallel Software class, my team developed an optimized raytracer. Without optimization, the raytracer takes 8 hours to render the Stanford Dragon model. After optimization, it takes 1 second!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cloud.githubusercontent.com/assets/2382481/4143264/7457b3f4-33c7-11e4-9f43-b68e8af5899a.png&quot; alt=&quot;Stanford Dragon&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 30 Nov 2014 14:02:44 -0800</pubDate>
        <link>http://h94h12.github.io/graphics/raytracer/optimized/parallel/2014/11/30/optimized-raytracer.html</link>
        <guid isPermaLink="true">http://h94h12.github.io/graphics/raytracer/optimized/parallel/2014/11/30/optimized-raytracer.html</guid>
        
        
        <category>graphics</category>
        
        <category>raytracer</category>
        
        <category>optimized</category>
        
        <category>parallel</category>
        
      </item>
    
      <item>
        <title>Tumscrapr</title>
        <description>&lt;p&gt;Tools: Python, web.py, OpenCV, BeautifulSoup, Selenium, PhantomJS, PIL, &lt;/p&gt;

&lt;p&gt;Won Best Beginner’s Hack at HackJam2014!&lt;/p&gt;

&lt;p&gt;After building a web crawler for &lt;a href=&quot;http://sergeykarayev.com/recognizing-image-style/&quot;&gt;computer vision research&lt;/a&gt;, I was inspired to put my newly learned scraping skills to use by using it to scrape Tumblr. I wanted to play around with image analysis, so I built this app that analyzes the aesthetic preferences of two Tumblr users. Given two users, it outputs a “match percentage” that says how similar their aesthetic tastes are.  My analysis has its shortcomings since it is only a quick hack, but it was still amusing to experiment with. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cloud.githubusercontent.com/assets/2382481/4154902/b3c30f18-3465-11e4-9558-7c6f24f94fe0.png&quot; alt=&quot;screen shot 2014-09-04 at 11 55 36 am&quot; /&gt;&lt;/p&gt;

&lt;p&gt;These two users both have a white minimalistic style, while the one on the left has a few more darker posts.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cloud.githubusercontent.com/assets/2382481/4154905/b67bbd68-3465-11e4-912c-bc68fc5e3a35.png&quot; alt=&quot;screen shot 2014-09-04 at 11 56 59 am&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Lower match, since we’re comparing minimalism to B&amp;amp;W portraits. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cloud.githubusercontent.com/assets/2382481/4154908/b7e76616-3465-11e4-92d4-f1c89051d015.png&quot; alt=&quot;screen shot 2014-09-04 at 11 59 35 am&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Higher match, but not as high as the first example. The user on the right uses a bit more color. &lt;/p&gt;

&lt;p&gt;I used BeautifulSoup and Selenium to scrape the images of Tumblr sites. I decided to not use the Tumblr API since it could only give me twenty-ish images at a time, which was not enough for my purposes. The Selenium web driver allows me to combat the infinite scroll that Tumblr uses. It sets a large window and lets me “scroll down” to load more results. BeautifulSoup allowed me to only fetch the images from a user’s Tumblr posts and parse the image url. &lt;/p&gt;

&lt;h2 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h2&gt;

&lt;p&gt;Deciding on how the image comparision algorithm would work was a challenge. I had to decide on something fast and not overly advanced (no deep learning here!). I decided to use OpenCV’s histogram feature and defined similarity in terms of the RGB channels of an image. Luckily, OpenCV has a built in function for comparing histograms. This takes into account the color and “complexity” of images. For example, a minimalistic monochrome image and a cluttered colorful image will have a low comparision score. &lt;/p&gt;

&lt;p&gt;Defining how I should compare groups of images was another challenge. If a user has one image that is an outlier, it could skew the results. My algorithm compares one image in set A to every image in set B, then uses the highest match. Of course, this approach has its shortcomings. Set A could have only one image that is similar to images in Set B. With this one image, the similarity between A and B can be very high. The algorithm has unpredictable results if users A and B do not have clear aesthetic tastes, i.e. their image posts follow no apparent trend. This is image-based analysis, so I’m not looking at which users the user likes to reblog from. &lt;/p&gt;

&lt;p&gt;The app outputs a comparison percentage, which is the average maximum comparison score between the two groups. &lt;/p&gt;

</description>
        <pubDate>Sat, 01 Mar 2014 14:02:44 -0800</pubDate>
        <link>http://h94h12.github.io/tumblr/scraping/web/crawler/python/2014/03/01/Tumscrapr.html</link>
        <guid isPermaLink="true">http://h94h12.github.io/tumblr/scraping/web/crawler/python/2014/03/01/Tumscrapr.html</guid>
        
        
        <category>tumblr</category>
        
        <category>scraping</category>
        
        <category>web</category>
        
        <category>crawler</category>
        
        <category>python</category>
        
      </item>
    
      <item>
        <title>Procedural Terrain Generation</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://github.com/h94h12/MT-Terrain&quot;&gt;Github&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Tools: C++, OpenGL&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cloud.githubusercontent.com/assets/2382481/4143559/47cee1a8-33cd-11e4-8804-4fe0a379f964.png&quot; alt=&quot;landscape&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This was the final project for my graphics class. I was inspired by generative art and how it allows computer science and visual arts to intersect, so procedural terrain generation seemed like a fun project. It combines many interesting elements: stochastic processes (for randomly generating the terrain), computational geometry (using Marching Tetrahedra algorithm) exploration of the terrain, and art (deciding on colors, appearances). &lt;/p&gt;

&lt;h2 id=&quot;algorithm&quot;&gt;Algorithm&lt;/h2&gt;
&lt;p&gt;The user is able to select from some implicit functions and the isosurface is extracted with the Marching Tetrahedra algorithm. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://cloud.githubusercontent.com/assets/2382481/4143560/49e8dcd2-33cd-11e4-9d49-1ac23276bf18.png&quot; alt=&quot;clovers17&quot; /&gt;
&lt;img src=&quot;https://cloud.githubusercontent.com/assets/2382481/4143561/4cf4f492-33cd-11e4-93cd-1f26623f0baa.png&quot; alt=&quot;fog&quot; /&gt;
&lt;img src=&quot;https://cloud.githubusercontent.com/assets/2382481/4143564/5038e366-33cd-11e4-86dc-1df92cd1059d.png&quot; alt=&quot;islands&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Mon, 30 Dec 2013 14:02:44 -0800</pubDate>
        <link>http://h94h12.github.io/graphics/procedural/terrain/generation/2013/12/30/Terrain.html</link>
        <guid isPermaLink="true">http://h94h12.github.io/graphics/procedural/terrain/generation/2013/12/30/Terrain.html</guid>
        
        
        <category>graphics</category>
        
        <category>procedural</category>
        
        <category>terrain</category>
        
        <category>generation</category>
        
      </item>
    
  </channel>
</rss>
